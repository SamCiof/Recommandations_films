from components.base_component import BaseComponent
import streamlit as st

class AnnoyComponent(BaseComponent):
    def __init__(self):
        super().__init__("Modèle Annoy")

    def display(self):
        st.header(self.title)
        st.markdown(self.get_model_test())
        st.markdown(self.get_loading_and_preparing_data())
        st.markdown(self.get_dimensionality_reduction_part1())
        st.image('images/annoy_dimensionality-reduction_with_TruncatedSVD.png')
        st.markdown(self.get_dimensionality_reduction_part2())
        st.image('images/annoy_dimensionality-reduction_with_TruncatedSVD_and_100_components.png')
        st.markdown(self.get_testing_different_metrics_and_numbers_of_trees())
        st.markdown(self.get_model_test_after_optimisation())
        st.markdown(self.get_model_interpretability_part1())
        st.image('images/annoy_heatmap_features_by_component.png')
        st.markdown(self.get_model_interpretability_part2())
        st.image('images/annoy_2D_screening_of_Films_after_SVD_with_Star_Trek.png')
        st.image('images/annoy_2D_screening_of_Films_after_SVD_with_recommandation_films.png')
        st.markdown(self.get_model_interpretability_part3())
        st.image('images/annoy_euclidean_distance_between_Star_Trek_and_recommended_movies.png')
        st.markdown(self.get_model_interpretability_part4())
        st.markdown(self.get_conclusion())


    def get_model_test(self):
        return ("""
        ### Test du modèle 
        Dans le cadre de notre projet sur les systèmes de recommandation, nous avons tenté d’élaborer un modèle hybride combinant les techniques de filtrage basées
        sur le contenu et le filtrage collaboratif. 
        Ce modèle utilise notamment Annoy (Approximate Nearest Neighbors Oh Yeah) une libraire de python utilisée par Spotify pour leur recommandation musicale. 
        Notre objectif était de créer un système capable de fournir des recommandations précises et personnalisées aux utilisateurs.
        """)
    
    def get_loading_and_preparing_data(self):
        return ("""
        **Chargement et Préparation des données :**\n    
        Une fois les données chargées, nous avons entrepris plusieurs étapes de préparation pour optimiser leur utilisation dans notre modèle de recommandation.
        Tout d'abord, nous avons retiré du dataframe la colonne imdbId, qui ne nous était plus utile pour la suite des opérations. Ensuite, nous avons ajouté une 
        nouvelle colonne, weightedAverageRating, afin de calculer la note moyenne pondérée (WAR) pour chaque film. Cette étape a permis d’ajouter une pondération 
        aux notes des films, prenant en compte à la fois la moyenne des notes et le nombre de votes, ce qui permet d'obtenir une estimation plus fiable et équilibrée
        de la qualité d'un film. Par ailleurs, étant donné que l'algorithme Annoy ne supporte que des données de type entier, nous avons converti toutes les colonnes 
        pertinentes en entiers. 
        Enfin, nous avons sélectionné la colonne title comme cible, que nous avons stockée à côté du jeu de données de features de contenu.
        """)
    
    def get_dimensionality_reduction_part1(self):
        return ("""
        **Réduction de la Dimensionnalité avec TruncatedSVD :**\n    
        Après la normalisation des données, nous avons cherché à déterminer le nombre optimal de composantes pour la décomposition par TruncatedSVD. Pour ce faire, 
        nous avons créé un graphique en utilisant 300 composantes, afin d'analyser visuellement le point à partir duquel l'ajout de nouvelles composantes n'apporte
        plus de gain significatif en termes de variance expliquée.
        """)

    
    def get_dimensionality_reduction_part2(self):
        return ("""
        L'analyse graphique a révélé que 100 composantes représentaient un choix optimal, car la variance expliquée cumulée atteignait 33,88% à ce stade, et 
        commençait à stagner au-delà. En comparaison, avec 300 composantes, la variance expliquée n'était que légèrement supérieure, atteignant 35,40%. Cette 
        stagnation après 100 composantes indique qu'au-delà de ce point, l'ajout de nouvelles composantes n'apporte qu'un gain marginal, justifiant ainsi notre 
        choix de retenir 100 composantes pour le modèle.
        """)
    
    def get_testing_different_metrics_and_numbers_of_trees(self):
        return (""" 
        **Test des différentes Métriques et nombres d’arbres :**\n    
        Après avoir déterminé le nombre optimal de composantes pour TruncatedSVD, nous avons procédé à des tests pour évaluer différentes combinaisons de métriques 
        et de nombres d'arbres afin de déterminer les paramètres les plus appropriés pour notre modèle.
        Nous avons expérimenté plusieurs métriques et quantités d'arbres pour identifier la configuration la plus performante sur ce jeu de données. Après de nombreux
        essais, il s’est avéré que l’utilisation de la métrique Euclidean combinée avec 10 arbres offrait les meilleurs résultats. 
        """)
    
    def get_model_test_after_optimisation(self):
        return (""" 
        **Tests du Modèle :**\n   
        Après avoir construit et optimisé le modèle, nous l'avons soumis à des tests en l'appliquant à plusieurs films pour évaluer la qualité des recommandations générées.
        Les résultats obtenus étaient non seulement pertinents, mais également cohérents avec les attentes, ce qui a confirmé l'efficacité du modèle.
        En plus de fournir des recommandations précises, le modèle s'est avéré être rapide à charger et à exécuter, ce qui le rend non seulement performant en termes de 
        précision, mais aussi pratique à utiliser dans un environnement de production. 
        """)
    
    def get_model_interpretability_part1(self):
        return (""" 
        ### Interprétabilité du modèle
        Ensuite, nous avons procédé à des analyses d’interprétation du modèle en utilisant SHAP (SHapley Additive exPlanations), en prenant le film Star Trek comme exemple. 
        SHAP nous a permis de comprendre comment le modèle prenait ses décisions en identifiant les colonnes les plus influentes pour chaque recommandation.
        L’analyse a révélé que le modèle organise les colonnes en composants principaux, et que certains de ces composants ont un impact significatif sur les recommandations 
        en fonction des caractéristiques spécifiques du film cible. Par exemple, pour Star Trek, certains composants étaient plus déterminants dans le processus de recommandation, 
        influençant directement les films proposés en relation avec celui-ci. 
        """)
    
    def get_model_interpretability_part2(self):
        return ("""
        Par la suite, nous avons visualisé en 2D l’espace entre les films afin de mieux comprendre comment le modèle choisit les films après avoir sélectionné les composants 
        les plus appropriés pour les recommandations. Cette visualisation a révélé que le modèle classe les films en fonction de la proximité de leurs attributs dans le dataframe. 
        Par exemple, les films associés aux genres Action, Adventure, et Crime sont regroupés ensemble. Pour confirmer nos analyses et conclusions sur le fonctionnement du modèle, 
        nous avons également visualisé cette projection en prenant Toy Story comme film de référence.
        """)
    
    def get_model_interpretability_part3(self):
        return ("""
        Enfin, nous avons zoomé sur les 5 films recommandés par le modèle pour Star Trek, ce qui a confirmé que le modèle privilégie les films ayant la plus faible distance par 
        rapport au film cible.      
        """)
    
    def get_model_interpretability_part4(self):
        return ("""
        Cette approche nous a permis de valider la cohérence des recommandations générées par le modèle, tout en offrant une meilleure visibilité sur le fonctionnement interne 
        du modèle et sur la manière dont les différentes caractéristiques des films contribuent aux recommandations finales.     
        """)
    
    def get_conclusion(self):
        return ("""
        ### Conclusion 
        En conclusion, le modèle basé sur la librairie Annoy s'est révélé être le plus performant parmi ceux que nous avons testés. Il a démontré une grande rapidité lors du 
        chargement et de l'exécution, tout en utilisant moins de mémoire que les autres modèles. En outre, il a fourni les résultats les plus pertinents, offrant des recommandations 
        de films cohérentes et fiables. Grâce à son efficacité et à sa précision, ce modèle s'est avéré être la meilleure option pour notre système de recommandation.
        """)
    

